---
- name: Skip addon installation on non-primary control nodes
  meta: end_host
  when: run_k8s_addons_on_host is defined and inventory_hostname != run_k8s_addons_on_host

- name: Ensure deployment directories exist
  file:
    path: "{{ item }}"
    state: directory
    owner: root
    group: root
    mode: "0755"
  loop:
    - /opt/deploy-k8s
    - "{{ k8s_manifests_remote_dir }}"
    - "{{ k8s_values_remote_dir }}"

- name: Check installed Helm version
  command: /usr/local/bin/helm version --short
  register: helm_current_version
  changed_when: false
  failed_when: false
  check_mode: false

- name: Normalize installed Helm semver
  set_fact:
    helm_current_version_semver: "{{ helm_current_version.stdout | regex_search('v[0-9]+\\.[0-9]+\\.[0-9]+') | default('') }}"

- name: Resolve Helm release architecture
  set_fact:
    helm_platform_arch: "{{ helm_cli_arch_map[ansible_architecture] | default('') }}"

- name: Fail when architecture is unsupported for pinned Helm binary
  fail:
    msg: >-
      Unsupported architecture '{{ ansible_architecture }}' for Helm {{ helm_cli_version }}.
      Add mapping/checksum in helm_cli_arch_map and helm_cli_sha256.
  when: helm_platform_arch == ''

- name: Download pinned Helm archive
  get_url:
    url: "https://get.helm.sh/helm-v{{ helm_cli_version }}-linux-{{ helm_platform_arch }}.tar.gz"
    dest: "/tmp/helm-v{{ helm_cli_version }}-linux-{{ helm_platform_arch }}.tar.gz"
    checksum: "sha256:{{ helm_cli_sha256[helm_platform_arch] }}"
    owner: root
    group: root
    mode: "0644"
  when: helm_current_version_semver != ('v' ~ helm_cli_version)

- name: Unpack pinned Helm archive
  unarchive:
    src: "/tmp/helm-v{{ helm_cli_version }}-linux-{{ helm_platform_arch }}.tar.gz"
    dest: /tmp
    remote_src: true
  when:
    - helm_current_version_semver != ('v' ~ helm_cli_version)
    - not ansible_check_mode

- name: Install pinned Helm binary
  copy:
    src: "/tmp/linux-{{ helm_platform_arch }}/helm"
    dest: /usr/local/bin/helm
    remote_src: true
    owner: root
    group: root
    mode: "0755"
  when:
    - helm_current_version_semver != ('v' ~ helm_cli_version)
    - not ansible_check_mode

- name: Remove Helm installation artifacts
  file:
    path: "{{ item }}"
    state: absent
  loop:
    - "/tmp/helm-v{{ helm_cli_version }}-linux-{{ helm_platform_arch }}.tar.gz"
    - "/tmp/linux-{{ helm_platform_arch }}"
  when: helm_current_version_semver != ('v' ~ helm_cli_version)

- name: Configure Helm repositories
  shell: |
    set -euo pipefail
    /usr/local/bin/helm repo add traefik https://traefik.github.io/charts --force-update
    /usr/local/bin/helm repo add jetstack https://charts.jetstack.io --force-update
    /usr/local/bin/helm repo add grafana https://grafana.github.io/helm-charts --force-update
    /usr/local/bin/helm repo add prometheus-community https://prometheus-community.github.io/helm-charts --force-update
    /usr/local/bin/helm repo update
  args:
    executable: /bin/bash
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  changed_when: false

- name: Ensure remote manifest subdirectories exist
  file:
    path: "{{ k8s_manifests_remote_dir }}/{{ item }}"
    state: directory
    owner: root
    group: root
    mode: "0755"
  loop:
    - system
    - workloads
    - observability

- name: Copy Helm values files to controller host
  copy:
    src: "{{ k8s_manifest_src_dir }}/values/{{ item }}"
    dest: "{{ k8s_values_remote_dir }}/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  loop: "{{ k8s_values_files }}"

- name: Copy Kubernetes manifests to controller host
  copy:
    src: "{{ k8s_manifest_src_dir }}/{{ item }}"
    dest: "{{ k8s_manifests_remote_dir }}/{{ item }}"
    owner: root
    group: root
    mode: "0644"
  loop: "{{ k8s_manifest_apply_order }}"

- name: Ensure cert-manager namespace exists
  shell: |
    set -euo pipefail
    k3s kubectl create namespace cert-manager --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  register: cert_manager_ns
  changed_when: "'created' in cert_manager_ns.stdout or 'configured' in cert_manager_ns.stdout"

- name: Install or upgrade cert-manager
  command: >-
    /usr/local/bin/helm upgrade --install {{ cert_manager_release_name }} {{ cert_manager_chart_ref }}
    --namespace cert-manager
    --version {{ cert_manager_chart_version }}
    --values {{ k8s_values_remote_dir }}/cert-manager-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: cert_manager_helm
  changed_when: >-
    'has been upgraded' in cert_manager_helm.stdout or
    'has been installed' in cert_manager_helm.stdout

- name: Ensure dp-system namespace exists
  shell: |
    set -euo pipefail
    k3s kubectl create namespace dp-system --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  register: dp_system_ns
  changed_when: "'created' in dp_system_ns.stdout or 'configured' in dp_system_ns.stdout"

- name: Stage GitHub App private key on controller host
  copy:
    dest: /tmp/github-app-private-key.pem
    content: "{{ github_app_private_key | default('') }}"
    owner: root
    group: root
    mode: "0600"
  no_log: true
  when:
    - not ansible_check_mode
    - github_app_private_key | default('') | length > 0
    - github_app_id | default('') | length > 0

- name: Create GitHub App secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic github-app \
      --from-literal=app-id={{ (github_app_id | default('')) | quote }} \
      --from-file=private-key=/tmp/github-app-private-key.pem \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when:
    - github_app_private_key | default('') | length > 0
    - github_app_id | default('') | length > 0

- name: Remove staged GitHub App private key
  file:
    path: /tmp/github-app-private-key.pem
    state: absent
  when:
    - github_app_private_key | default('') | length > 0
    - github_app_id | default('') | length > 0

- name: Create Temporal credentials secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic temporal-creds \
      --from-literal=cloud-api-key={{ (temporal_cloud_api_key | default('')) | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: temporal_cloud_api_key | default('') | length > 0

- name: Create Temporal worker config secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic temporal-worker-config \
      --from-literal=temporal-address={{ (temporal_address | default('')) | quote }} \
      --from-literal=temporal-namespace={{ (temporal_namespace | default('')) | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when:
    - temporal_address | default('') | length > 0
    - temporal_namespace | default('') | length > 0

- name: Create git-server-config secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic git-server-config \
      --from-literal=admin-token={{ git_server_admin_token | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: git_server_admin_token | default('') | length > 0

- name: Create Cloudflare token secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n cert-manager create secret generic cloudflare-api-token \
      --from-literal=api-token={{ cloudflare_api_token | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: cloudflare_api_token | default('') | length > 0

- name: Create PowerDNS TSIG key secret for cert-manager when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n cert-manager create secret generic powerdns-tsig-key \
      --from-literal=tsig-secret={{ powerdns_tsig_key | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: powerdns_tsig_key | default('') | length > 0

- name: Install or upgrade Traefik
  command: >-
    /usr/local/bin/helm upgrade --install {{ traefik_release_name }} {{ traefik_chart_ref }}
    --namespace dp-system
    --version {{ traefik_chart_version }}
    --values {{ k8s_values_remote_dir }}/traefik-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: traefik_helm
  changed_when: >-
    'has been upgraded' in traefik_helm.stdout or
    'has been installed' in traefik_helm.stdout

- name: Install or upgrade Loki
  command: >-
    /usr/local/bin/helm upgrade --install {{ loki_release_name }} {{ loki_chart_ref }}
    --namespace dp-system
    --version {{ loki_chart_version }}
    --values {{ k8s_values_remote_dir }}/loki-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: loki_helm
  changed_when: >-
    'has been upgraded' in loki_helm.stdout or
    'has been installed' in loki_helm.stdout

- name: Install or upgrade Promtail
  command: >-
    /usr/local/bin/helm upgrade --install {{ promtail_release_name }} {{ promtail_chart_ref }}
    --namespace dp-system
    --version {{ promtail_chart_version }}
    --values {{ k8s_values_remote_dir }}/promtail-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: promtail_helm
  changed_when: >-
    'has been upgraded' in promtail_helm.stdout or
    'has been installed' in promtail_helm.stdout

- name: Install or upgrade Prometheus stack
  command: >-
    /usr/local/bin/helm upgrade --install {{ prometheus_release_name }} {{ prometheus_chart_ref }}
    --namespace dp-system
    --version {{ prometheus_chart_version }}
    --values {{ k8s_values_remote_dir }}/prometheus-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: prometheus_helm
  changed_when: >-
    'has been upgraded' in prometheus_helm.stdout or
    'has been installed' in prometheus_helm.stdout

- name: Create Alertmanager Slack webhook secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic alertmanager-slack \
      --from-literal=slack-webhook-url={{ slack_webhook_url | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: slack_webhook_url | default('') | length > 0

- name: Create Grafana Slack webhook secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic grafana-slack \
      --from-literal=SLACK_WEBHOOK_URL={{ slack_webhook_url | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: slack_webhook_url | default('') | length > 0

- name: Install or upgrade Grafana
  command: >-
    /usr/local/bin/helm upgrade --install {{ grafana_release_name }} {{ grafana_chart_ref }}
    --namespace dp-system
    --version {{ grafana_chart_version }}
    --values {{ k8s_values_remote_dir }}/grafana-values.yml
  environment:
    KUBECONFIG: "{{ k8s_kubeconfig_path }}"
  register: grafana_helm
  changed_when: >-
    'has been upgraded' in grafana_helm.stdout or
    'has been installed' in grafana_helm.stdout

- name: Create database credentials secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic db-credentials \
      --from-literal=url={{ db_credentials_url | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: db_credentials_url | default('') | length > 0

- name: Stage Firebase service account JSON on controller host
  copy:
    dest: /tmp/firebase-service-account.json
    content: "{{ firebase_service_account_json | default('') }}"
    owner: root
    group: root
    mode: "0600"
  when: firebase_service_account_json | default('') | length > 0

- name: Create API server config secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic api-server-config \
      --from-literal=auth-jwt-secret={{ auth_jwt_secret | quote }} \
      --from-literal=auth-apikey-encryption-key={{ auth_apikey_encryption_key | quote }} \
      --from-literal=auth-frontend-url={{ auth_frontend_url | quote }} \
      --from-literal=github-client-id={{ github_oauth_client_id | quote }} \
      --from-literal=github-client-secret={{ github_oauth_client_secret | quote }} \
      --from-literal=githubapp-client-id={{ github_app_client_id | quote }} \
      --from-literal=githubapp-client-secret={{ github_app_client_secret | quote }} \
      --from-literal=githubapp-webhook-secret={{ github_app_webhook_secret | quote }} \
      --from-literal=cloudflare-api-token={{ cloudflare_api_token | quote }} \
      --from-literal=cloudflare-zone-id={{ cloudflare_zone_id | quote }} \
      --from-literal=turso-api-key={{ turso_api_key | quote }} \
      --from-literal=turso-org-slug={{ turso_org_slug | quote }} \
      --from-file=firebase-service-account-json=/tmp/firebase-service-account.json \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when:
    - auth_jwt_secret | default('') | length > 0
    - firebase_service_account_json | default('') | length > 0

- name: Remove staged Firebase service account JSON
  file:
    path: /tmp/firebase-service-account.json
    state: absent
  when: firebase_service_account_json | default('') | length > 0

- name: Create Loki basic-auth secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic loki-auth-secret \
      --from-literal=users={{ loki_basic_auth_users | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: loki_basic_auth_users | default('') | length > 0

- name: Create Prometheus basic-auth secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret generic prometheus-auth-secret \
      --from-literal=users={{ prometheus_basic_auth_users | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: prometheus_basic_auth_users | default('') | length > 0

- name: Apply Kubernetes manifests
  command: "k3s kubectl apply -f {{ k8s_manifests_remote_dir }}/{{ item }}"
  register: apply_manifest_cmd
  changed_when: >-
    ' created' in apply_manifest_cmd.stdout or
    ' configured' in apply_manifest_cmd.stdout
  loop: "{{ k8s_manifest_apply_order }}"

- name: Install customer quota reconciler script
  copy:
    dest: /usr/local/bin/customer-quota-reconciler.sh
    owner: root
    group: root
    mode: "0755"
    content: |
      #!/usr/bin/env bash
      set -euo pipefail

      selector='{{ customer_quota_namespace_selector }}'
      namespaces="$(k3s kubectl get namespaces -l "${selector}" -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}')"

      if [[ -z "${namespaces}" ]]; then
        exit 0
      fi

      for ns in ${namespaces}; do
        k3s kubectl -n "${ns}" create quota quota \
          --hard=pods={{ customer_quota_pods }},requests.cpu={{ customer_quota_requests_cpu }},requests.memory={{ customer_quota_requests_memory }},limits.cpu={{ customer_quota_limits_cpu }},limits.memory={{ customer_quota_limits_memory }} \
          --dry-run=client -o yaml | k3s kubectl apply -f -
      done

- name: Install customer quota reconciler systemd service
  copy:
    dest: /etc/systemd/system/customer-quota-reconciler.service
    owner: root
    group: root
    mode: "0644"
    content: |
      [Unit]
      Description=Reconcile ResourceQuota for customer namespaces
      Wants=k3s.service
      After=k3s.service

      [Service]
      Type=oneshot
      ExecStart=/usr/local/bin/customer-quota-reconciler.sh

- name: Install customer quota reconciler systemd timer
  copy:
    dest: /etc/systemd/system/customer-quota-reconciler.timer
    owner: root
    group: root
    mode: "0644"
    content: |
      [Unit]
      Description=Periodic ResourceQuota reconciliation for customer namespaces

      [Timer]
      OnBootSec=30s
      OnUnitActiveSec={{ customer_quota_timer_interval }}
      Unit=customer-quota-reconciler.service

      [Install]
      WantedBy=timers.target

- name: Reload systemd daemon after quota reconciler units
  command: systemctl daemon-reload
  changed_when: false

- name: Enable and start customer quota reconciler timer
  systemd:
    name: customer-quota-reconciler.timer
    enabled: true
    state: started

- name: Run customer quota reconciliation once now
  command: /usr/local/bin/customer-quota-reconciler.sh
  changed_when: false

# --- CI/CD deploy user (GitHub Actions → SSH → kubectl set image) ---

- name: Create deploy user for CI/CD
  user:
    name: deploy
    shell: /bin/bash
    create_home: true
    system: false

- name: Create deploy user .ssh directory
  file:
    path: /home/deploy/.ssh
    state: directory
    owner: deploy
    group: deploy
    mode: "0700"

- name: Stage deploy SSH private key
  copy:
    dest: /tmp/deploy_ssh_key
    content: "{{ deploy_ssh_private_key }}"
    owner: root
    group: root
    mode: "0600"
  when:
    - not ansible_check_mode
    - deploy_ssh_private_key | default('') | length > 0
  no_log: true

- name: Derive and install deploy SSH authorized_keys
  shell: |
    set -euo pipefail
    ssh-keygen -y -f /tmp/deploy_ssh_key > /home/deploy/.ssh/authorized_keys
    chown deploy:deploy /home/deploy/.ssh/authorized_keys
    chmod 600 /home/deploy/.ssh/authorized_keys
  args:
    executable: /bin/bash
  when: deploy_ssh_private_key | default('') | length > 0

- name: Remove staged deploy SSH key
  file:
    path: /tmp/deploy_ssh_key
    state: absent

- name: Ensure kubectl symlink exists for deploy user
  file:
    src: /usr/local/bin/kubectl
    dest: /usr/bin/kubectl
    state: link
    force: true
  failed_when: false

- name: Create deploy user .kube directory
  file:
    path: /home/deploy/.kube
    state: directory
    owner: deploy
    group: deploy
    mode: "0700"

- name: Wait for ci-deployer service account token
  shell: |
    set -euo pipefail
    k3s kubectl get secret ci-deployer-token -n dp-system -o jsonpath='{.data.token}'
  args:
    executable: /bin/bash
  register: ci_deployer_token_check
  until: ci_deployer_token_check.rc == 0 and ci_deployer_token_check.stdout | length > 0
  retries: 12
  delay: 5
  changed_when: false
  check_mode: false

- name: Generate restricted kubeconfig for deploy user
  shell: |
    set -euo pipefail
    TOKEN=$(k3s kubectl get secret ci-deployer-token -n dp-system -o jsonpath='{.data.token}' | base64 -d)
    CA=$(k3s kubectl get secret ci-deployer-token -n dp-system -o jsonpath='{.data.ca\.crt}')
    cat > /home/deploy/.kube/config <<EOF
    apiVersion: v1
    kind: Config
    clusters:
      - cluster:
          certificate-authority-data: $CA
          server: https://127.0.0.1:6443
        name: k3s
    contexts:
      - context:
          cluster: k3s
          namespace: dp-system
          user: ci-deployer
        name: ci-deployer
    current-context: ci-deployer
    users:
      - name: ci-deployer
        user:
          token: $TOKEN
    EOF
    chown deploy:deploy /home/deploy/.kube/config
    chmod 600 /home/deploy/.kube/config
  args:
    executable: /bin/bash

- name: Create ghcr.io pull secret when provided
  shell: |
    set -euo pipefail
    k3s kubectl -n dp-system create secret docker-registry ghcr-pull-secret \
      --docker-server=ghcr.io \
      --docker-username=gluonfield \
      --docker-password={{ ghcr_pull_token | quote }} \
      --dry-run=client -o yaml | k3s kubectl apply -f -
  args:
    executable: /bin/bash
  when: ghcr_pull_token | default('') | length > 0
